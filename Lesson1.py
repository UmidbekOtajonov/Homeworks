"""
1. Why do you think companies analyze large volumes of data?
companies analyze large volyumes of data to gain insights, identify trends, improve decision-making,
optimize operations.

2. If analyzing and sorting large data manually in exel is difficult,
how do you think python can help solve this problem?
Python can help automate repetitive tasks, handle large datasets efficiently,and provide powerful
libraries like pandas, numpy for data manipulation . It allows faster processing , advanced analytics,
integrations and visualizations.Python can help this problem.

3. Imagine you work at a sale company that receives data about 10000 customer transactions
daily. How would you analyze data?
I would use python with pandas to load, clean the data,analysis to identify sales trends,
customer behavior and product performance.Matplotlib or seaborn  would help visualization.

4. In your opinion , what tasks can Python be useful for in bi process?
Python is useful for:
data cleaning and transformation,
integration with multiple data source,
visualization of KPIs and dashboards,
statistical analysis and predictive modeling,
automating etl processes.

5. If you wanted to compare a company's profit year by year,
 how could this be done using Python?
I would use pandas to group transaction or financial data by year,
calculate total profit for each year,visualize the comparison using matplotlib
with a bar chart or line chart.
6.  If you don't know Python ,what difficulties might you face when working
with large datasets?
Tools like exel or manual methods often slow down.
Whithout of python repetitive tasks like cleaning , sorting, merging data must be done
manually , which is time-consuming and error-prone.
Limited analytical capabilities.
While Excel offers charts, it struggles with interactive dashboards or complex visualizations
that Python libraries (like matplotlib, seaborn, or Plotly) handle easily.



"""